---
title: "Data Sources Overview"
---

## Canadian Outline {#sec-canada-outline}

#### Source and Description

The dataset, titled **Canada Outline**, was generated to create a simplified polygon of Canada's national boundaries. This dataset was produced using the [GADM](https://gadm.org) Level 1 administrative boundary data for Canada, with the geometry simplified for efficient large-scale spatial analysis [@gadm2023]. The resulting GeoPackage file represents Canada and its provinces/territories with reduced geometric complexity. The dataset is suitable for mapping and spatial analysis tasks requiring simplified boundaries.

#### Processing Steps

The processed data was generated using the `prc_canada_outline` script. The following steps were undertaken:

1. **Data Acquisition**:
   - GADM Level 1 administrative boundary data for Canada was retrieved using the `geodata::gadm` function.
2. **Geometry Simplification**:
   - Simplified the polygon geometry to reduce data complexity using the `terra::simplifyGeom` function with a tolerance of 0.1.
3. **Output Generation**:
   - The simplified boundary dataset was saved as `can_1_simplified.gpkg` in GeoPackage format.


#### Processed Data Structure

The structure of the simplified dataset is as follows:

```{r}
#| label: tbl-canada-outline
#| tbl-cap: "Structure of the simplified Canada outline dataset"
data.frame(
  Column_Name = c(
    "gid_1", "gid_0", "country", "name_1", "varname_1", "nl_name_1",
    "type_1", "engtype_1", "cc_1", "hasc_1", "iso_1", "geom"
  ),
  Description = c(
    "Unique identifier for the first administrative level.",
    "Country code for Canada.",
    "Name of the country (Canada).",
    "Name of the first administrative level (Province/Territory).",
    "Alternative or variant names for the region.",
    "Native language names for the region.",
    "Type of administrative unit (Province/Territory).",
    "English type name for the administrative unit.",
    "Internal code for the administrative region.",
    "Hierarchical administrative subdivision code.",
    "ISO code for the administrative region.",
    "Simplified polygon geometry for the region."
  )
) |>
  knitr::kable()
```


## Canadian Freshwater Fish Species {#sec-freshwater-fish}

#### Source and Description

The dataset, titled **FishBase Freshwater Species Checklist**, was harvested from [FishBase](https://www.fishbase.se/) [@fishbase2024]. This dataset provides information on freshwater fish species found across Canada. It includes essential taxonomic and ecological details, such as species name, vernacular name, family, order, and occurrence status. Additional datasets retrieved from FishBase include species status (e.g., threat categories from the [IUCN Red List of Threatened Species](https://www.iucnredlist.org/)), and whether the species is classified as game or commercial. The source data consists of HTML tables retrieved through web scraping and transformed into a structured format for analysis.

#### Processing Steps

The harvested raw data was processed using the `prc_freshwater_fish_canada` script. The following steps were performed:

1. **Data Cleaning**: 
   - Column names in all input files were standardized using the `janitor::clean_names` function.
   - Unnecessary columns, such as `name_in_country`, were removed.
2. **Field Selection and Renaming**:
   - The `fish_base_name` column was renamed to `vernacular` for clarity.
3. **Integration**:
   - Species occurrence data was joined with additional tables for status, game species, and commercial species using the `species` column as a key.
4. **Data Transformation**:
   - A unique `species_id` was generated for each species record.
5. **Data Export**:
   - The fully integrated and processed dataset was saved as `freshwater_fish_species_canada.csv`.

#### Processed Data Structure

The processed dataset retains the following structure:

```{r}
#| label: tbl-freshwater-fish-extended
#| tbl-cap: "Structure of the processed freshwater fish species dataset for Canada"
data.frame(
  Column_Name = c("species_id", "species", "vernacular", "order", "family", "occurrence", "threat_category", "game", "commercial"),
  Description = c(
    "Unique identifier for each fish species entry.",
    "Scientific name of the fish species.",
    "Common name of the fish species.",
    "Taxonomic order to which the species belongs.",
    "Taxonomic family to which the species belongs.",
    "Occurrence status of the species in Canada (e.g., native).",
    "Threat category assigned to the species, if applicable (e.g., Vulnerable (VU), Endangered (EN)).",
    "Indicator of whether the species is classified as a game species (1 = yes, NA = no).",
    "Indicator of whether the species is classified as a commercial species (1 = yes, NA = no)."
  )
) |>
  knitr::kable()
```


## Canadian Hydrological Features {#sec-canadian-hydrology}

#### Source and Description

The dataset, titled **Atlas of Canada National Scale Data 1:1,000,000 - Waterbodies & Rivers**, was harvested from [Natural Resources Canada](https://open.canada.ca/data/en/dataset/e9931fc7-034c-52ad-91c5-6c64d4ba0065) [@nrcan2022a; @nrcan2022b]. This comprehensive GIS dataset includes spatial and tabular data representing Canada's hydrological features. It consists of waterbodies and river datasets compiled for large-scale mapping at a 1:1,000,000 scale. The processed dataset provides geospatial layers of lakes and rivers, including both their polygonal representations and sampled points for further spatial analyses.

#### Processing Steps

The harvested raw data was processed using the `prc_atlas_of_canada_hydrology` script. The following steps were performed:

1. **Unzipping**: The compressed GDB files were extracted to a temporary directory for processing.
2. **Lake Processing**:
   - Loaded the "AC_1M_Waterbodies" layer using the `sf::st_read` function.
   - Calculated the area and perimeter of each lake using `sf::st_area` and `lwgeom::st_perimeter_lwgeom`.
   - Filter lakes to keep only lakes with area > 5 $km^2$.
   - Generated a unique `waterbody_id` for each lake and classified it as type `lake`.
   - Retained relevant columns: `waterbody_id`, `wb_type`, `name`, `name_fr`, `area`, and `perimeter`.
   - Transformed the data to CRS 4326 and exported it as `lakes_polygons.gpkg`.
   - Generated centroids for each lake and exported the point layer as `lakes_points.gpkg`.
3. **River Processing**:
   - Loaded the "AC_1M_Rivers_dense" layer using the `sf::st_read` function.
   - Calculated the length of each river segment using `sf::st_length`.
   - Filter lakes to keep only lakes with length > 10 km.
   - Generated a unique `waterbody_id` for each river and classified it as type `river`.
   - Retained relevant columns: `waterbody_id`, `wb_type`, `name`, `name_fr`, and `length`.
   - Transformed the data to CRS 4326 and exported it as `rivers_lines.gpkg`.
   - Sampled points along each river segment at the mid-point of each rivers, cast the lines to points, and exported as `rivers_points.gpkg`.
4. **Cleanup**: Temporary files created during processing were deleted.

#### Processed Data Structure

The structure of the processed lake polygon dataset is as follows:

```{r}
#| label: tbl-lakes-polygons
#| tbl-cap: "Structure of the processed lake polygon dataset for Canada"
data.frame(
  Column_Name = c("waterbody_id", "wb_type", "name", "name_fr", "area", "perimeter"),
  Description = c(
    "Unique identifier for each lake feature.",
    "Type of waterbody, always 'lake' for this dataset.",
    "Name of the lake in English.",
    "Name of the lake in French.",
    "Surface area of the lake in square kilometers.",
    "Perimeter of the lake in kilometers."
  )
) |>
  knitr::kable()
```

The structure of the processed lake point dataset is as follows:

```{r}
#| label: tbl-lakes-points
#| tbl-cap: "Structure of the processed lake point dataset for Canada"
data.frame(
  Column_Name = c("waterbody_id", "geom"),
  Description = c(
    "Unique identifier for each lake feature.",
    "Centroid geometry of the lake in geographic coordinates (CRS 4326)."
  )
) |>
  knitr::kable()
```

The structure of the processed river line dataset is as follows:

```{r}
#| label: tbl-rivers-lines
#| tbl-cap: "Structure of the processed river line dataset for Canada"
data.frame(
  Column_Name = c("waterbody_id", "wb_type", "name", "name_fr", "length"),
  Description = c(
    "Unique identifier for each river segment.",
    "Type of waterbody, always 'river' for this dataset.",
    "Name of the river in English.",
    "Name of the river in French.",
    "Length of the river segment in kilometers."
  )
) |>
  knitr::kable()
```

The structure of the processed river point dataset is as follows:

```{r}
#| label: tbl-rivers-points
#| tbl-cap: "Structure of the processed river point dataset for Canada"
data.frame(
  Column_Name = c("waterbody_id", "geom"),
  Description = c(
    "Unique identifier for each river segment.",
    "Sampled point geometry at the mid-point of the river."
  )
) |>
  knitr::kable()
```

## Freshwater Fish Species Occurrences {#sec-freshwater-fish-occurrences}

#### Source and Description

The dataset, titled **Global Freshwater Fish Species Occurrences Database**, was retrieved from [Figshare](https://figshare.com/collections/A_global_database_on_freshwater_fish_species_occurrences_in_drainage_basins/3739145) [@figshare2025]. This comprehensive dataset compiles freshwater fish species occurrences aggregated at the drainage basin level. The data is associated with the data paper by @tedesco2017 and is designed for analyzing global freshwater biodiversity patterns. 

The dataset includes both spatial data (drainage basins) and tabular data (species occurrences). The drainage basin data covers 3,119 polygons worldwide, while the occurrence table provides over 110,000 records of species distributions across basins. The data has been validated using established taxonomic references such as FishBase.

#### Processing Steps

The harvested data was processed using the `prc_freshwater_fish_occurrences` script. The following steps were performed:

1. **Data Extraction**:
   - The compressed dataset (`freshwater_fish_occurrences.zip`) was unzipped into a temporary directory.
2. **Drainage Basin Data Processing**:
   - The shapefile `Basin042017_3119.shp` was loaded using the `sf::st_read` function.
   - Column names were cleaned and renamed to remove unnecessary prefixes using `janitor::clean_names` and `dplyr::rename_with`.
   - The cleaned data was exported as `bassins.gpkg` in GeoPackage format.
3. **Species Occurrence Data Processing**:
   - The `Occurrence_Table.csv` file was loaded using the `vroom::vroom` function.
   - Column names were cleaned and renamed similarly to the drainage basin data.
   - Species names in the `species_name_in_source` and `fishbase_valid_species_name` columns were updated to replace periods (`.`) with spaces.
   - The processed data was exported as `occurrences.csv`.

#### Processed Data Structure

The structure of the processed drainage basin dataset (`bassins.gpkg`) is as follows:

```{r}
#| label: tbl-bassins
#| tbl-cap: "Structure of the processed drainage basin dataset"
data.frame(
  Column_Name = c("basin_name", "country", "ecoregion", "endorheic", "out_longit", "out_latit", "med_longit", "med_latit", "surf_area", "geometry"),
  Description = c(
    "Name of the drainage basin.",
    "Country where the basin is located.",
    "Ecoregion associated with the basin.",
    "Indicator of whether the basin is endorheic (closed basin).",
    "Longitude of the basin outlet.",
    "Latitude of the basin outlet.",
    "Median longitude of the basin.",
    "Median latitude of the basin.",
    "Surface area of the basin in square kilometers.",
    "Polygon geometry of the basin."
  )
) |>
  knitr::kable()
```

The structure of the processed species occurrence dataset (`occurrences.csv`) is as follows:

```{r}
#| label: tbl-occurrences
#| tbl-cap: "Structure of the processed species occurrence dataset"
data.frame(
  Column_Name = c("basin_name", "species_name_in_source", "native_exotic_status", "tsn_itis_code", "fishbase_species_code", "fishbase_valid_species_name", "occurrence_status"),
  Description = c(
    "Name of the drainage basin.",
    "Species name as recorded in the source.",
    "Status of the species in the basin (native or exotic).",
    "Taxonomic Serial Number (TSN) from ITIS.",
    "Species code from FishBase.",
    "Valid species name from FishBase.",
    "Occurrence status of the species in the basin (valid or invalid)."
  )
) |>
  knitr::kable()
```


## GBIF Species Occurrences {#sec-gbif-species-occurrences}

#### Source and Description

The dataset, titled **GBIF Occurrence Data**, was retrieved from the [Global Biodiversity Information Facility (GBIF)](https://www.gbif.org/) [@gbif2025]. This dataset compiles species occurrence records for a specified taxonomic group and geographic region. The retrieved dataset includes spatial and tabular data for over 850,000 records of species occurrences across Canada, starting from 2000. 

It should be noted that the processing steps described below show how the data is downloaded and processed programmatically. However, due to how GBIF manages their data request, we elected to store the downloaded data on our secure Google Cloud Storage and to retrieve them programmatically from there rather than directly on GBIF.

#### Processing Steps

The harvested data was processed using the `dwn_gbif` and `prc_gbif` scripts. The following steps were performed:

1. **Data Download**:
   - A query for specified taxonomic groups and geographic boundaries was submitted to the GBIF API using the `rgbif` package.
2. **Data Extraction**:
   - The compressed ZIP file was extracted into a temporary directory.
   - The occurrence data was read from `occurrence.txt` using the `vroom::vroom` function.
3. **Data Cleaning and Transformation**:
   - Selected relevant columns: `species`, `year`, `month`, `day`, `eventDate`, `decimalLatitude`, `decimalLongitude`, and `lifeStage`.
   - Converted the cleaned data to a spatial data frame using the `sf::st_as_sf` function with geographic coordinates (CRS 4326).
4. **Export**:
   - The cleaned and spatially enabled dataset was exported as `species_occurrences_gbif.gpkg` in GeoPackage format.

#### Processed Data Structure

The structure of the processed dataset (`species_occurrences_gbif.gpkg`) is as follows:

```{r}
#| label: tbl-gbif-occurrences
#| tbl-cap: "Structure of the processed GBIF occurrence dataset"
data.frame(
  Column_Name = c("species", "year", "month", "day", "eventDate", "lifeStage", "geometry"),
  Description = c(
    "Scientific name of the species.",
    "Year of the recorded occurrence.",
    "Month of the recorded occurrence.",
    "Day of the recorded occurrence.",
    "Full date and time of the recorded occurrence.",
    "Life stage of the species at the time of the occurrence (if available).",
    "Point geometry of the occurrence in geographic coordinates (CRS 4326)."
  )
) |>
  knitr::kable()
```


## National Hydro Network {#sec-national-hydro-network}

#### Source and Description

The dataset, titled **National Hydro Network (NHN) GeoBase Series**, was retrieved from [Natural Resources Canada](https://open.canada.ca/data/en/dataset/a4b190fe-e090-4e6d-881e-b87956c07977) [@nrcan2022]. This dataset provides a comprehensive geometric description and a set of basic attributes describing Canada's inland surface waters. The data includes lakes, reservoirs, rivers, canals, drainage networks, and associated features. 

#### Processing Steps

The NHN data was processed using the `prc_national_hydro_network` script. The following steps were performed:

1. **Data Extraction**:
   - The compressed GeoPackage dataset (`rhn_nhn_decoupage.gpkg.zip`) was unzipped into a temporary directory.
2. **Watershed Data Processing**:
   - The GeoPackage file (`rhn_nhn_decoupage.gpkg`) was read using the `sf::st_read` function.
   - All geometries were cast to polygons using `sf::st_cast("GEOMETRYCOLLECTION")` and `sf::st_collection_extract("POLYGON")`.
   - The geometries were simplified using `sf::st_simplify(dTolerance = 100)` to reduce complexity while maintaining accuracy.
   - A unique `watershed_id` was generated for each feature using the `dplyr::mutate` function.
   - Only the `watershed_id` and geometry columns were retained.
3. **Export**:
   - The processed watershed data was exported as `watersheds.gpkg` in GeoPackage format.

#### Processed Data Structure

The structure of the processed dataset (`watersheds.gpkg`) is as follows:

```{r}
#| label: tbl-watersheds
#| tbl-cap: "Structure of the processed watershed dataset"
data.frame(
  Column_Name = c("watershed_id", "geom"),
  Description = c(
    "Unique identifier for each watershed feature.",
    "Polygon geometry of the watershed in geographic coordinates (CRS 4326)."
  )
) |>
  knitr::kable()
```



## References
